<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Thyssen Wen's Blog</title><meta name="author" content="Thyssen Wen"><meta name="copyright" content="Thyssen Wen"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="既然选择远方，就要风雨兼程">
<meta property="og:type" content="website">
<meta property="og:title" content="Thyssen Wen&#39;s Blog">
<meta property="og:url" content="https://thinksky5124.github.io/index.html">
<meta property="og:site_name" content="Thyssen Wen&#39;s Blog">
<meta property="og:description" content="既然选择远方，就要风雨兼程">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://avatars.githubusercontent.com/u/40914433?v=4">
<meta property="article:author" content="Thyssen Wen">
<meta property="article:tag" content="既然选择远方，就要风雨兼程">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://avatars.githubusercontent.com/u/40914433?v=4"><link rel="shortcut icon" href="https://avatars.githubusercontent.com/u/40914433?v=4"><link rel="canonical" href="https://thinksky5124.github.io/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Thyssen Wen\'s Blog',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2024-04-16 16:59:16'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="Thyssen Wen's Blog" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://avatars.githubusercontent.com/u/40914433?v=4" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">23</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">25</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">17</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.dlut.edu.cn/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('https://s2.loli.net/2024/03/25/TXt51eJvamH9bjP.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="Thyssen Wen's Blog"><span class="site-name">Thyssen Wen's Blog</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.dlut.edu.cn/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">Thyssen Wen's Blog</h1><div id="site-subtitle"><span id="subtitle"></span></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left"><a href="/2024/04/16/hello-world/" title="Hello World"><img class="post-bg" src="https://s2.loli.net/2024/03/25/TXt51eJvamH9bjP.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hello World"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/04/16/hello-world/" title="Hello World">Hello World</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-04-16T08:57:05.647Z" title="发表于 2024-04-16 16:57:05">2024-04-16</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-04-16T08:57:05.647Z" title="更新于 2024-04-16 16:57:05">2024-04-16</time></span></div><div class="content">Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.
Quick StartCreate a new post1$ hexo new "My New Post"

More info: Writing
Run server1$ hexo server

More info: Server
Generate static files1$ hexo generate

More info: Generating
Deploy to remote sites1$ hexo deploy

More info: Deployment
</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2024/03/25/TensorRT_deploy_and_infer/" title="TensorRT 模型构建与推理"><img class="post-bg" src="https://s2.loli.net/2024/03/25/TXt51eJvamH9bjP.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="TensorRT 模型构建与推理"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/03/25/TensorRT_deploy_and_infer/" title="TensorRT 模型构建与推理">TensorRT 模型构建与推理</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-03-25T03:17:41.679Z" title="发表于 2024-03-25 11:17:41">2024-03-25</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-03-25T03:17:41.971Z" title="更新于 2024-03-25 11:17:41">2024-03-25</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E9%AB%98%E6%95%88%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">高效人工智能</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/TensorRT/">TensorRT</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/TensorRT/">TensorRT</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/">模型部署</a></span></div><div class="content">TensorRT 模型构建与推理TensorRT 简介TensorRT 是由 NVIDIA 发布的深度学习框架，用于在其硬件上运行深度学习推理。TensorRT 提供量化感知训练和离线量化功能，用户可以选择 INT8 和 FP16 两种优化模式，将深度学习模型应用到不同任务的生产部署，如视频流、语音识别、推荐、欺诈检测、文本生成和自然语言处理。TensorRT 经过高度优化，可在 NVIDIA GPU 上运行， 并且可能是目前在 NVIDIA GPU 运行模型最快的推理引擎。关于 TensorRT 更具体的信息可以访问 TensorRT官网 了解。
安装 TensorRTWindows默认在一台有 NVIDIA 显卡的机器上，提前安装好 CUDA 和 CUDNN，登录 NVIDIA 官方网站下载和主机 CUDA 版本适配的 TensorRT 压缩包即可。
以 CUDA 版本是 10.2 为例，选择适配 CUDA 10.2 的 zip 包，下载完成后，有 conda 虚拟环境的用户可以优先切换到虚拟环境中，然后在 powershell 中执行类似如下的命令安装并测试：
123456cd  ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2022/08/18/CPU_GPU%E8%81%94%E5%90%88%E7%BC%96%E7%A8%8B/" title="CPU/GPU联合编程"><img class="post-bg" src="https://s2.loli.net/2024/03/25/UbvDSp43CogyTzO.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CPU/GPU联合编程"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/08/18/CPU_GPU%E8%81%94%E5%90%88%E7%BC%96%E7%A8%8B/" title="CPU/GPU联合编程">CPU/GPU联合编程</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-08-18T08:00:00.000Z" title="发表于 2022-08-18 16:00:00">2022-08-18</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-04-16T08:57:05.643Z" title="更新于 2024-04-16 16:57:05">2024-04-16</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/">分布式训练</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/">分布式训练</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%B7%A5%E7%A8%8B/">工程</a></span></div><div class="content">CPU/GPU联合编程由示例代码可以知道，只要调用了 cuda 函数把模型移动到 GPU 之上，我们就可以使用 CUDA global 核函数在GPU上进行并行运算。
12345678model = ToyModel().cuda(device_ids[0]) # 这里复制模型到 GPU 之上ddp_model = DDP(model, device_ids)loss_fn = nn.MSELoss()optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)optimizer.zero_grad()outputs = ddp_model(torch.randn(20, 10))

但是我们忽略了一个问题，就是 PyTorch 怎么知道此时应该调用GPU对应的 global 核函数？为什么 PyTorch 就不调用 CPU 函数或者其他设备的函数了？这就是我们接下来需要分析的。
Dispatcher 机制在PyTorch中，operator 所表现出预期行为是由很多机制共同作用导致的，比如：

做实际工作的kernel。
是否支持反向 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2022/08/18/CUDA%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/" title="CUDA编程模型基础"><img class="post-bg" src="https://s2.loli.net/2024/03/25/UbvDSp43CogyTzO.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CUDA编程模型基础"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/08/18/CUDA%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/" title="CUDA编程模型基础">CUDA编程模型基础</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-08-18T08:00:00.000Z" title="发表于 2022-08-18 16:00:00">2022-08-18</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-04-16T08:57:05.643Z" title="更新于 2024-04-16 16:57:05">2024-04-16</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/">分布式训练</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/">分布式训练</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%B7%A5%E7%A8%8B/">工程</a></span></div><div class="content">CUDA编程模型基础CUDA是英伟达为GPU编程提供的异构编程库。
异构模型CUDA编程模型是一个异构模型。程序运行在一个异构系统之上，这个异构系统由CPU和GPU构成，它们之间由总线分开，程序运行时候是由CPU和GPU协同工作。
在CUDA之中，有两个重要概念：host和device。

Host ：CPU及其内存。
Device ：GPU及其内存。

因此，CUDA 架构下的一个程序也对应分为两个部份：Host 代码和Device代码，它们分别在CPU和GPU上运行。host与device之间可以通信进行数据拷贝。

主机代码（Host Code）：在 CPU 上执行的部份，使用Linux（GNU gcc）和Windows（Microsoft Visual C）编译器来编译。大致可以认为认为C语言工作对象是CPU和内存条。
设备代码（Device Code）：在GPU上执行的部份，使用 NVIDIA NVCC 编译器来编译。大致可以认为 CUDA C工作对象是GPU及GPU上内存（也叫设备内存）。

123456789101112131415161718+------------- ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2022/08/18/Dispatcher/" title="Dispatcher"><img class="post-bg" src="https://s2.loli.net/2024/03/25/UbvDSp43CogyTzO.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Dispatcher"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/08/18/Dispatcher/" title="Dispatcher">Dispatcher</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-08-18T08:00:00.000Z" title="发表于 2022-08-18 16:00:00">2022-08-18</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-04-16T08:57:05.643Z" title="更新于 2024-04-16 16:57:05">2024-04-16</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/">分布式训练</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/">分布式训练</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%B7%A5%E7%A8%8B/">工程</a></span></div><div class="content">Dispatcher我们接下来通过源码来看看。
虚函数表
Schema 例子
  每个kernel 算子（虚函数）都有一个对应的schema，我们可以从 aten/src/ATen/native/native_functions.yaml 之中找到一些虚函数 schema 的例子，这些都是以字符串的形式呈现。我们可以看到，schema 包括算子名称（比如zero_sparse_），输入参数个数和类型，返回值类型，是否需要check，如何分发等等。
  123456789101112131415161718192021222324252627# zero 操作对应的虚函数表- func: zero_(Tensor(a!) self) -&gt; Tensor(a!)  device_check: NoCheck   # TensorIterator  variants: method, function  dispatch:    CPU, CUDA: zero_    Meta: zero_meta_    SparseCPU, SparseCUDA: zero_sparse_     ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2022/08/18/DistributedDataParallel_%E5%88%9D%E5%A7%8B%E5%8C%96%E6%96%B9%E6%B3%95&amp;%E5%AD%98%E5%82%A8/" title="DistributedDataParallel 初始化方法&amp;存储"><img class="post-bg" src="https://s2.loli.net/2024/03/25/UbvDSp43CogyTzO.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="DistributedDataParallel 初始化方法&amp;存储"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/08/18/DistributedDataParallel_%E5%88%9D%E5%A7%8B%E5%8C%96%E6%96%B9%E6%B3%95&amp;%E5%AD%98%E5%82%A8/" title="DistributedDataParallel 初始化方法&amp;存储">DistributedDataParallel 初始化方法&amp;存储</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-08-18T08:00:00.000Z" title="发表于 2022-08-18 16:00:00">2022-08-18</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-04-16T08:57:05.647Z" title="更新于 2024-04-16 16:57:05">2024-04-16</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/">分布式训练</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/">分布式训练</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%B7%A5%E7%A8%8B/">工程</a></span></div><div class="content">DistributedDataParallel 初始化方法&amp;存储回顾基本概念关于分布式通信，PyTorch 提供的几个概念是：进程组，后端，初始化，Store。

进程组&nbsp;：DDP是真正的分布式训练，可以使用多台机器来组成一次并行运算的任务。为了能够让 DDP 的各个worker之间通信，PyTorch 设置了进程组这个概念。
后端&nbsp;：后端这个概念是一个逻辑上的概念。本质上后端是一种IPC通信机制。
初始化&nbsp;: 虽然有了后端和进程组的概念，但是如何让 worker 在建立进程组之前发现彼此？ 这就需要一种初始化方法来告诉大家传递一个信息：如何联系到其它机器上的进程。
Store&nbsp;: 可以认为是分布式键值存储，利用这个存储就可以在组中的进程之间共享信息以及初始化分布式包 （通过显式创建存储来作为init_method的替代）。

初始化进程组在调用任何 DDP 其他方法之前，需要使用torch.distributed.init_process_group()进行初始化。该方法会初始化默认分布式进程组和分布式包。此方法会阻塞，直到所有进程都加 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2022/08/18/DistributedDataParallel_%E6%80%BB%E8%BF%B0&amp;%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8/" title="DistributedDataParallel 总述&amp;如何使用"><img class="post-bg" src="https://s2.loli.net/2024/03/25/UbvDSp43CogyTzO.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="DistributedDataParallel 总述&amp;如何使用"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/08/18/DistributedDataParallel_%E6%80%BB%E8%BF%B0&amp;%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8/" title="DistributedDataParallel 总述&amp;如何使用">DistributedDataParallel 总述&amp;如何使用</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-08-18T08:00:00.000Z" title="发表于 2022-08-18 16:00:00">2022-08-18</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-04-16T08:57:05.647Z" title="更新于 2024-04-16 16:57:05">2024-04-16</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/">分布式训练</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/">分布式训练</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%B7%A5%E7%A8%8B/">工程</a></span></div><div class="content">DistributedDataParallel 总述&amp;如何使用数据并行因为DistributedDataParallel 是数据并行，所以首先通过两个图，复习一下什么是数据并行。
我们可以看到，模型并行与数据并行的区别。

第二张图来自fairscale github源码，清晰的给出了一个数据并行的运行模式，具体包括：
模型分片，本地前向计算，本地反向传播，AllReduce来同步梯度，本地更新梯度这几步。

DDP 运行逻辑Torch.distributed 包 为多个计算节点的 PyTorch 提供多进程并行通信原语，可以并行化跨进程和跨集群的计算。torch.nn.parallel.DistributedDataParallel基于torch.distributed 包的功能提供了一个同步分布式训练wrapper，这个wrapper可以对 PyTorch 模型封装进行训练。其核心功能是基于多进程级别的通信，与Multiprocessing package - torch.multiprocessing&nbsp;和 DataParrallel 提供的并行性有明显区别。
以 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2022/08/18/PyTorch%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/" title="PyTorch分布式训练"><img class="post-bg" src="https://s2.loli.net/2024/03/25/UbvDSp43CogyTzO.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="PyTorch分布式训练"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/08/18/PyTorch%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/" title="PyTorch分布式训练">PyTorch分布式训练</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-08-18T08:00:00.000Z" title="发表于 2022-08-18 16:00:00">2022-08-18</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-04-16T08:57:05.647Z" title="更新于 2024-04-16 16:57:05">2024-04-16</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/">分布式训练</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/">分布式训练</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%B7%A5%E7%A8%8B/">工程</a></span></div><div class="content">PyTorch分布式训练数据并行训练PyTorch 为数据并行训练提供了多种选项。一般来说，应用会从简单到复杂，从原型到量产。这些应用共同的发展轨迹是：

如果数据和模型可以放在一个 GPU 中，并且不关心训练速度，就使用单设备（single-device）训练。
如果服务器上有多个 GPU，并且您希望以最少的代码更改来加速训练，那么可以使用单机多 GPU DataParallel。
如果您想进一步加快训练速度并愿意编写更多代码来设置它，可以使用单机多 GPU DistributedDataParallel。
如果应用程序需要跨机器边界进行扩展，请使用多机 DistributedDataParallel 和&nbsp;启动脚本。
如果预期会出现错误（例如，OOM）或者资源可以在训练期间动态加入和离开，则使用torchelastic启动分布式训练。


Torch如何使用GPU

_apply 方法
遍历 _parameters：
对参数调用fn进行处理，得到param_applied。
用 param_applied 重新设置参数。


如果参数有梯度，则：
对参数的grad调用fn进 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2022/08/18/SLAM_math_fundation/" title="SLAM数学基础"><img class="post-bg" src="https://s2.loli.net/2024/03/25/UbvDSp43CogyTzO.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="SLAM数学基础"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/08/18/SLAM_math_fundation/" title="SLAM数学基础">SLAM数学基础</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-08-18T08:00:00.000Z" title="发表于 2022-08-18 16:00:00">2022-08-18</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-04-16T08:57:05.647Z" title="更新于 2024-04-16 16:57:05">2024-04-16</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/SLAM/">SLAM</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/SLAM/">SLAM</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/">数学原理</a></span></div><div class="content">SLAM数学基础三维空间的刚体运动刚体：刚体是指在运动中和受力作用后，形状和大小不变，而且内部各点的相对位置不变的物体。
旋转矩阵$$ SO(n)={R \in \mathbb{R}^{n \times n}|R R^T = I, det(R)=1} $$
$SO(n)$是特殊正交群，刚体在两个坐标系之间的变换可以公式化表述为
$$ a’=Ra+t $$
$t$表示的是从a坐标系原点到b坐标系原点的向量
三维旋转矩阵的计算如下
$$\begin{bmatrix}    e^T_1 e’_1 &amp; e^T_1 e’_2 &amp; e^T_1 e’_3\    e^T_2 e’_1 &amp; e^T_2 e’_2 &amp; e^T_2 e’_3 \    e^T_3 e’_1 &amp; e^T_3 e’_2 &amp; e^T_3 e’_3\\end{bmatrix}$$
$e_i$是某一坐标系的基向量
齐次坐标连续变换坐标系时，使用上述的变换公式不是线性的表述，写起来会很麻烦，如
$$c=R_2(R_1a+t_1)+t_2$$
因而在三维向量的末尾加上一个1，就变为了四维向 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2022/08/18/%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96/" title="权重初始化"><img class="post-bg" src="https://s2.loli.net/2024/03/25/UbvDSp43CogyTzO.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="权重初始化"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/08/18/%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96/" title="权重初始化">权重初始化</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-08-18T08:00:00.000Z" title="发表于 2022-08-18 16:00:00">2022-08-18</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-04-16T08:57:05.647Z" title="更新于 2024-04-16 16:57:05">2024-04-16</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96/">模型优化</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96/">模型优化</a></span></div><div class="content">模型优化kaiming初始化的推导
权重初始化为什么需要权重初始化网络训练的过程中，容易出现梯度消失（梯度特别的接近0）和梯度爆炸（梯度特别的大）的情况，导致大部分反向传播得到的梯度不起作用或者起反作用。研究人员希望能够有一种好的权重初始化方法：让网络前向传播或者反向传播的时候，卷积的输出和前传的梯度比较稳定。合理的方差既保证了数值一定的不同，又保证了数值一定的稳定。（通过卷积权重的合理初始化, 让计算过程中的数值分布稳定）
推导的先验知识
参照上面的卷积图，对输入的特征图进行的卷积。具体要研究的是输出的一个点的方差(紫色点)。所以是通过黄色的输入(个)和绿色的卷积参数(个)去计算一个输出值(紫色输出)的方差。&nbsp;一个点对应于原论文里面的说法为a response。感觉这个是理解权重初始化的重点。基于独立同分布的强假设：输入的每个值都是独立同分布的，所以和独立同分布的参数进行卷积得到结果的分布也是相同的。所以其他的3个输出点的方差也是一样的。进一步说，虽然输入是个不同的值。但是我们可以这样认为：有一个满足某分布的随机变量，然后随机抽样48次，这48个值就可以组成了输入，且独立同 ...</div></div></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="/page/2/#content-inner">2</a><a class="page-number" href="/page/3/#content-inner">3</a><a class="extend next" rel="next" href="/page/2/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://avatars.githubusercontent.com/u/40914433?v=4" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Thyssen Wen</div><div class="author-info__description">既然选择远方，就要风雨兼程</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">23</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">25</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">17</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Thinksky5124"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">不定期更新Blog，主要研究图像方面的人工智能，人工智能硬件等</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/04/16/hello-world/" title="Hello World"><img src="https://s2.loli.net/2024/03/25/TXt51eJvamH9bjP.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hello World"/></a><div class="content"><a class="title" href="/2024/04/16/hello-world/" title="Hello World">Hello World</a><time datetime="2024-04-16T08:57:05.647Z" title="发表于 2024-04-16 16:57:05">2024-04-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/03/25/TensorRT_deploy_and_infer/" title="TensorRT 模型构建与推理"><img src="https://s2.loli.net/2024/03/25/TXt51eJvamH9bjP.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="TensorRT 模型构建与推理"/></a><div class="content"><a class="title" href="/2024/03/25/TensorRT_deploy_and_infer/" title="TensorRT 模型构建与推理">TensorRT 模型构建与推理</a><time datetime="2024-03-25T03:17:41.679Z" title="发表于 2024-03-25 11:17:41">2024-03-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/08/18/CPU_GPU%E8%81%94%E5%90%88%E7%BC%96%E7%A8%8B/" title="CPU/GPU联合编程"><img src="https://s2.loli.net/2024/03/25/UbvDSp43CogyTzO.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CPU/GPU联合编程"/></a><div class="content"><a class="title" href="/2022/08/18/CPU_GPU%E8%81%94%E5%90%88%E7%BC%96%E7%A8%8B/" title="CPU/GPU联合编程">CPU/GPU联合编程</a><time datetime="2022-08-18T08:00:00.000Z" title="发表于 2022-08-18 16:00:00">2022-08-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/08/18/CUDA%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/" title="CUDA编程模型基础"><img src="https://s2.loli.net/2024/03/25/UbvDSp43CogyTzO.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CUDA编程模型基础"/></a><div class="content"><a class="title" href="/2022/08/18/CUDA%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/" title="CUDA编程模型基础">CUDA编程模型基础</a><time datetime="2022-08-18T08:00:00.000Z" title="发表于 2022-08-18 16:00:00">2022-08-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/08/18/Dispatcher/" title="Dispatcher"><img src="https://s2.loli.net/2024/03/25/UbvDSp43CogyTzO.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Dispatcher"/></a><div class="content"><a class="title" href="/2022/08/18/Dispatcher/" title="Dispatcher">Dispatcher</a><time datetime="2022-08-18T08:00:00.000Z" title="发表于 2022-08-18 16:00:00">2022-08-18</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            <a class="card-more-btn" href="/categories/" title="查看更多">
    <i class="fas fa-angle-right"></i></a>
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/TensorRT/"><span class="card-category-list-name">TensorRT</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AD%A6%E4%B9%A0/"><span class="card-category-list-name">人工智能学习</span><span class="card-category-list-count">4</span></a><ul class="card-category-list child"><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AD%A6%E4%B9%A0/%E6%96%AF%E5%9D%A6%E7%A6%8FCS221%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8A%80%E6%9C%AF/"><span class="card-category-list-name">斯坦福CS221人工智能原理与技术</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AD%A6%E4%B9%A0/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"><span class="card-category-list-name">目标检测</span><span class="card-category-list-count">3</span></a><ul class="card-category-list child"><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AD%A6%E4%B9%A0/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"><span class="card-category-list-name">基础知识</span><span class="card-category-list-count">1</span></a></li></ul></li></ul></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/"><span class="card-category-list-name">分布式训练</span><span class="card-category-list-count">7</span></a><ul class="card-category-list child"><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="card-category-list-name">深度学习</span><span class="card-category-list-count">7</span></a></li></ul></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/"><span class="card-category-list-name">并行计算</span><span class="card-category-list-count">4</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/TensorRT/" style="font-size: 1.1em; color: #999">TensorRT</a> <a href="/tags/SPP-Net/" style="font-size: 1.1em; color: #999">SPP-Net</a> <a href="/tags/%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/" style="font-size: 1.1em; color: #999">模型部署</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 1.5em; color: #99a9bf">深度学习</a> <a href="/tags/%E8%BF%81%E7%A7%BB%E5%8D%9A%E5%AE%A2/" style="font-size: 1.1em; color: #999">迁移博客</a> <a href="/tags/CMU%E8%AF%BE%E7%A8%8B/" style="font-size: 1.3em; color: #99a1ac">CMU课程</a> <a href="/tags/Faster-RCNN/" style="font-size: 1.1em; color: #999">Faster-RCNN</a> <a href="/tags/SLAM/" style="font-size: 1.1em; color: #999">SLAM</a> <a href="/tags/%E5%B7%A5%E7%A8%8B/" style="font-size: 1.37em; color: #99a4b2">工程</a> <a href="/tags/Git/" style="font-size: 1.1em; color: #999">Git</a> <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/" style="font-size: 1.1em; color: #999">人工智能导论</a> <a href="/tags/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/" style="font-size: 1.3em; color: #99a1ac">并行计算</a> <a href="/tags/tensorflow/" style="font-size: 1.1em; color: #999">tensorflow</a> <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AD%A6%E4%B9%A0/" style="font-size: 1.1em; color: #999">人工智能学习</a> <a href="/tags/hexo/" style="font-size: 1.1em; color: #999">hexo</a> <a href="/tags/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" style="font-size: 1.17em; color: #999c9f">数字图像处理</a> <a href="/tags/%E6%96%AF%E5%9D%A6%E7%A6%8F%E8%AF%BE%E7%A8%8B/" style="font-size: 1.1em; color: #999">斯坦福课程</a> <a href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/" style="font-size: 1.17em; color: #999c9f">图像处理基本概念</a> <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/" style="font-size: 1.43em; color: #99a6b9">分布式训练</a> <a href="/tags/%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/" style="font-size: 1.1em; color: #999">代码实现</a> <a href="/tags/%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96/" style="font-size: 1.17em; color: #999c9f">模型优化</a> <a href="/tags/%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/" style="font-size: 1.1em; color: #999">数学原理</a> <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 1.23em; color: #999ea6">目标检测</a> <a href="/tags/pytorch/" style="font-size: 1.17em; color: #999c9f">pytorch</a> <a href="/tags/%E8%B8%A9%E5%9D%91/" style="font-size: 1.1em; color: #999">踩坑</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/04/"><span class="card-archive-list-date">四月 2024</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/03/"><span class="card-archive-list-date">三月 2024</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/08/"><span class="card-archive-list-date">八月 2022</span><span class="card-archive-list-count">10</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/07/"><span class="card-archive-list-date">七月 2022</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/01/"><span class="card-archive-list-date">一月 2021</span><span class="card-archive-list-count">7</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/12/"><span class="card-archive-list-date">十二月 2020</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/11/"><span class="card-archive-list-date">十一月 2020</span><span class="card-archive-list-count">1</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">23</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2024-04-16T08:59:15.616Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By Thyssen Wen</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>window.typedJSFn = {
  init: (str) => {
    window.typed = new Typed('#subtitle', Object.assign({
      strings: str,
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50,
    }, null))
  },
  run: (subtitleType) => {
    if (true) {
      if (typeof Typed === 'function') {
        subtitleType()
      } else {
        getScript('https://cdn.jsdelivr.net/npm/typed.js@2.1.0/dist/typed.umd.min.js').then(subtitleType)
      }
    } else {
      subtitleType()
    }
  }
}
</script><script>function subtitleType () {
  if (true) {
    typedJSFn.init(["既然选择远方，就要风雨兼程","分享自己学习技术记录点滴生活...","所有的不平凡都来自平凡"])
  } else {
    document.getElementById("subtitle").textContent = "既然选择远方，就要风雨兼程"
  }
}
typedJSFn.run(subtitleType)</script><script>(() => {
  const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaid.length === 0) return
  const runMermaid = () => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    Array.from($mermaid).forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
      const mermaidID = 'mermaid-' + index
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)

      const renderV10 = () => {
        renderFn.then(({svg}) => {
          mermaidSrc.insertAdjacentHTML('afterend', svg)
        })
      }

      const renderV9 = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      typeof renderFn === 'string' ? renderV9(renderFn) : renderV10()
    })
  }

  const loadMermaid = () => {
    window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid@10.8.0/dist/mermaid.min.js').then(runMermaid)
  }

  btf.addGlobalFn('themeChange', runMermaid, 'mermaid')

  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.13.0"></script></div></div></body></html>